---
title: 空品預報時距之延長
tags: GFS WRF CMAQ forecast
layout: article
aside:
  toc: true
sidebar:
  nav: layouts
date:  2022-12-06
modify_date: 2022-12-06 14:12:19
---

## 背景

- 目前全球預報產品的時距(leading time)、[GFS][GFS]事實上是有348個小時，即為16天整([目前使用前5天][fcst5])。空氣品質[CAMS][CAMS]有120小時即為5天、[WACCM][WACCM]則由昨天開始到未來9天共10天預報。
- 延長時距的挑戰在於
  - [電腦計算時間](#os控制之背景同步執行)延長一倍，原來5天預報還可以壓縮在6個小時之內，早晨上班還可以看到更新之預報，延長1倍到12小時似乎就失去每天預報的價值。
  - [各領域風場的相依性](#風場的整合)：雖然每一層都已開啟[FDDA][FDDA]，然而因時間延長一倍、風場非線性發展的可能性增加，上層模擬結果與下層有可能發生嚴重落差，需加強各層之間的連結。
  - [東亞邊界檔案的整併](#waccm數據之應用)：目前看來WACCM模擬似乎有低估的情形，而CAMS只有5天預報(嚴格講是昨天開始的5天、就是4天)，如何應用?
  - [排放量檔案擴大、跨月整合](#排放量預備程式之修正)：原本逐月排放量檔案已延常到下月初，然而並未有10天這麼長，終究還是要解決跨月的整併問題。

## 風場的整合

### 延長時距遭遇的困難

- 原來1、2層雙向巢狀網格、第3層獨立邊界的作法，導致第5天在第2層邊界上發生質量不守恆的情形，造成CMAQ跳出。
- 3層雙向巢狀網格的做法會需要6個小時的計算時間，為不可行方案。

### ndown方案

- 藉由ndown程式讀取1/2層雙向巢狀網格中第2層wrfout檔案，從當中切割出第3層的邊界條件，取代第3層單獨的real作業。
- 作法詳見[ndown][ndown]
- 基本設定：因為需要起訖時間，因此還是再做一遍。

```bash
kuang@master /nas1/backup/data/NOAA/NCEP/GFS/YYYY
$ cat ndown.cs

today=$(date -d -0day +%Y%m%d)
yestd=$(date -d -1day +%Y%m%d)
yesty=$(date -d -1day +%Y)
gfs=/nas1/backup/data/NOAA/NCEP/GFS/YYYY
cmaq=/home/cmaqruns/2022fcst
fcst=/nas2/cmaqruns/2022fcst
BEGD=$(date -d "$today -0days" +%Y-%m-%d)
ENDD=$(date -d "$BEGD  +11days" +%Y-%m-%d)

DOM=( 'CWBWRF_45k' 'SECN_9k' 'TWEPA_3k' 'tw_CWBWRF_45k' 'nests3')
MPI=( '-f machinefile -np 200' '-f machinefile -np 196' '-f machinefile -np 140' '-f machinefile -np 120' '-f machinefile -np 120')


yea1=$(echo $BEGD|cut -d'-' -f1);mon1=$(echo $BEGD|cut -d'-' -f2);day1=$(echo $BEGD|cut -d'-' -f3)
yea2=$(echo $ENDD|cut -d'-' -f1);mon2=$(echo $ENDD|cut -d'-' -f2);day2=$(echo $ENDD|cut -d'-' -f3)
dates=()
for id in {0..11};do
  dates=( ${dates[@]} $(date -d "$BEGD +${id}days" +%Y-%m-%d) )
done
yea1=$(echo $BEGD|cut -d'-' -f1);mon1=$(echo $BEGD|cut -d'-' -f2);day1=$(echo $BEGD|cut -d'-' -f3)
yea2=$(echo $ENDD|cut -d'-' -f1);mon2=$(echo $ENDD|cut -d'-' -f2);day2=$(echo $ENDD|cut -d'-' -f3)
```

- 製作第2,3層real所需的namelist.input

```bash
i=2
cd $gfs/${DOM[$i]}/ndown
cp namelist.input23_loop namelist.input
  for cmd in "s/SYEA/$yea1/g" "s/SMON/$mon1/g" "s/SDAY/$day1/g" \
             "s/EYEA/$yea2/g" "s/EMON/$mon2/g" "s/EDAY/$day2/g" ;do
    sed -i $cmd namelist.input
  done
```

- 清除檔案並建立新的連結

```bash
for hd in metoa_em wrf;do if compgen -G "${hd}*" > /dev/null; then rm -f ${hd}*;fi;done

for d in 2 3;do
  dd=$(( $d - 1 ))
  for id in {0..11};do
    for j in $(ls ../../met_em.d0${d}.${dates[$id]}_*);do
      k=${j/d0${d}/d0${dd}}
      l=${k/..\/..\//}
      m=${l/met_/metoa_};ln -s $j $m;done;done;done
```

- 執行大陸東南與台灣等2層的real.exe
  - 大陸東南重複執行了，但似乎也沒有辦法減省。
  - 第3層(台灣)單獨執行real.exe的結果不能用來執行ndown.exe

```bash
LD_LIBRARY_PATH=/nas1/WRF4.0/WRFv4.3/WRFV4/LIBRARIES/lib:/opt/intel_f/compilers_and_libraries_2020.0.166/linux/compiler/lib/intel64_lin:/opt/mpich/mpich-3.4.2-icc/lib /opt/mpich/mpich-3.4.2-icc/bin/mpirun ${MPI[$i]} /nas1/WRF4.0/WRFv4.3/WRFV4/main/real.exe >& /dev/null
```

- 準備執行ndown.exe

```bash
mv wrfinput_d02 wrfndi_d02

for id in {0..10};do ln -sf $gfs/${DOM[3]}/wrfout_d02_${dates[$id]}_00:00:00 wrfout_d01_${dates[$id]}_00:00:00;done

sed -i 's/interval_seconds                    = 10800/interval_seconds                    = 3600/g' namelist.input
```

- 執行ndown.exe
  - ndown.exe執行還算快速，用10個核心就夠了
  - 將目錄下的執行結果移動到TWEPA_3目錄，以備第3層(單層)wrf之執行。此處的第2層即為TWEPA_3目錄的第1層

```bash
#ndown.exe is intel version
LD_LIBRARY_PATH=/nas1/WRF4.0/WRFv4.3/WRFV4/LIBRARIES/lib:/opt/intel_f/compilers_and_libraries_2020.0.166/linux/compiler/lib/intel64_lin:/opt/intel_f/compilers_and_libraries_2020.0.166/linux/mpi/intel64/lib:/opt/intel_f/compilers_and_libraries_2020.0.166/linux/mpi/intel64/lib/release:/opt/intel/compilers_and_libraries_2020.0.166/linux/mpi/intel64/libfabric/lib /opt/intel_f/compilers_and_libraries_2020.0.166/linux/mpi/intel64/bin/mpirun -np 10 /nas1/WRF4.0/WRFv4.3/WRFV4/main/ndown.exe >& /dev/null

## restore the real and ndown results
cd $gfs/${DOM[$i]}
for f in wrfinput wrfbdy wrffdda wrflowinp;do
  mv ndown/${f}_d02 ${f}_d01
done
```

### ndown.cs下載點

- {% include download.html content="由大陸東南wrfout結果切割下層邊界條件之作業腳本[ndown.cs][ndowncs]" %}

## OS控制之背景同步執行

### WPS

- 下載gfs檔案後，序列化執行WPS之[ungrib][ungrib]與[metgrid][metgrid]花費將近40分鐘，如果分成各個gfs檔案個別(平行)轉檔，只需要5分鐘。
- 為避免[ungrib][ungrib]錯亂，每一個gfs檔案建立自己的目錄。先將WPS目錄下相關檔案都見好連結，每天的gfs檔名又是固定的，只需改變namelist.wps內的起迄時間即可。

```bash
#kuang@master /nas1/backup/data/NOAA/NCEP/GFS/YYYY
$ cat par_UGB.cs
gfs=/nas1/backup/data/NOAA/NCEP/GFS/YYYY
BEGD=$(date -d "$today -1days" +%Y-%m-%d)

for ((i=0;i <= 312; i+=3));do
  iii=$(printf "%03d" $i)
  NOWD=$(date -d "$BEGD +$(( $i + 6 ))hour" +%Y-%m-%d )
  hh=$(date -d "$BEGD +$(( $i + 6 ))hour" +%H )
  mkdir -p ${gfs}/f$iii
  cd ${gfs}/f$iii
  ./link_grib.csh gfs*
  cp ../namelist.wps_loop namelist.wps
  for cmd in 's/BEGD/'$NOWD'/g' 's/ENDD/'$NOWD'/g' 's/HH/'$hh'/g';do sed -ie $cmd namelist.wps;done

## ungrib and metgrid
  ~/bin/sub ../UGB2
done

# first time, link the WPS relatives
# for i in $(ls gfs*);do j=$(echo $i|cut -d'.' -f5);for k in $(ls|grep -v gfs|grep -v met_em|grep -v FILE|grep -v GRIBF|grep -v ^f|grep -v namelist);do cd $j;ln -s ../$k .;cd ..;done;done
```

- 執行[ungrib][ungrib]及[metgrid][metgrid]結束後，順便將結果移動到根目錄
- UGB2內之指令為序列執行

```bash
#kuang@master /nas1/backup/data/NOAA/NCEP/GFS/YYYY
#$ cat UGB2
LD_LIBRARY_PATH=/nas1/WRF4.0/WRFv4.3/WRFV4/LIBRARIES/lib:/opt/intel_f/compilers_and_libraries_2020.0.166/linux/compiler/lib/intel64_lin /nas1/WRF4.0/WRF_chem/WPS/ungrib/src/ungrib.exe >& /dev/null
LD_LIBRARY_PATH=/nas1/WRF4.0/WRFv4.3/WRFV4/LIBRARIES/lib:/opt/intel_f/compilers_and_libraries_2020.0.166/linux/compiler/lib/intel64_lin /nas1/WRF4.0/WRFv4.3/WPS/metgrid/src/metgrid.exe >& /dev/null
mv met_em* ..
```

- 下載(序列)、轉檔(平行)整體串連
- 趁下載的時間同步執行WPS程式

```bash
#kuang@master /nas1/backup/data/NOAA/NCEP/GFS/YYYY
#$ cat fcst.cs
...
# 執行gfs檔案下載
# execute ungrib and metgrid in background
for ((i=0;i <= 312; i+=3));do
  iii=$(printf "%03d" $i)
  file=gfs.t${BH}z.pgrb2.1p00.f$iii
  if [ -e $file ];then rm $file;fi
  while [ 1 ]; do
  $wget --no-check-certificate -q --retry-connrefused --waitretry=3 --random-wait \
        --read-timeout=20 --timeout=15 -t 10 --continue $root$dir$file
  if [ $? = 0 ]; then break; fi
  sleep 5
  done

  NOWD=$(date -d "$BEGD +$(( $i + 10#$BH ))hour" +%Y-%m-%d )
  hh=$(date -d "$BEGD +$(( $i + 10#$BH ))hour" +%H )
  mkdir -p ${gfs}/f$iii
  cd ${gfs}/f$iii
  ./link_grib.csh gfs*
  cp ../namelist.wps_loop namelist.wps
  for cmd in 's/BEGD/'$NOWD'/g' 's/ENDD/'$NOWD'/g' 's/HH/'$hh'/g';do sed -ie $cmd namelist.wps;done
  ~/bin/sub ../UGB2
  cd $gfs
done
...
```

### 排放量預備程式之同步執行

- 由於排放量與風場是互相獨立的，可以提前在風場模式之前，趁該等程式執行時，同步執行排放量預備程式。
- 見[排放量預備程式之同步執行](#排放量預備程式之同步執行)
  
### mcip之背景運作

- mcip雖然不會花太多時間，但加上後處理，3各領域共計約20分鐘，背景運作後這些時間都可以節省下來。
- 但要注意的是後處理，不論`add_firstHr.sh`或者是`brk_day2.cs`都是bash的腳本，而run_mcip則是csh腳本
- 解法：在run_mcip中以csh方式重寫

```bash
kuang@master /nas2/cmaqruns/2022fcst
$ tail -n20 run_mcip_DM.csh
mpirun -np $NP $ProgDir/${PROG}.exe #  >& /dev/null
if ( $status == 0 ) then
  rm fort.*
# add first hour
  foreach i ( GRIDBDY2D.nc  GRIDCRO2D.nc  GRIDDOT2D.nc  LUFRAC_CRO.nc \
              METCRO2D.nc  METCRO3D.nc  METDOT3D.nc  SOI_CRO.nc )
  ~/bin/sub ~/bin/add_firstHr.py ${i}
  end
  ~/bin/sub ~/bin/add_firstHr.py METBDY3D.nc
  /usr/bin/sh ~/bin/sub ~/bin/brk_day2.cs METBDY3D.nc
  if ( $DM == 'grid45' ) then
    /usr/bin/ncks -O  -d VAR,0 -v TFLAG,DENS METCRO3D.nc METCRO3D.DENS
    /usr/bin/sh ~/bin/sub ~/bin/brk_day2.cs METCRO3D.DENS >&/dev/null
  endif
  exit 0
else
  echo "Error running $PROG"
  exit 1
endif
```

- 如此run_mcip就可以獨立出來在背景執行了
- 執行下一個real(ndown)/wrf時來同步執行run_mcip
- 最後一層背景執行mcip需要while指令來確認其真的結束了，這各工作由wait_exe來執行(詳下說明)

```bash
#kuang@master /nas1/backup/data/NOAA/NCEP/GFS/YYYY
#$ cat fcst.cs
...
  # link the wrfout's and execute mcip(in the background)
  if [ $i == 3 ];then
    for d in 1 2;do
      j=$(( $d - 1))
      for f in {0..10};do
        wrfo=wrfout_d0${d}_${dates[$f]}_00:00:00
        nc1=$gfs/${DOM[$i]}/$wrfo
        if [ -e $nc1 ];then
          wrfo2=${wrfo/d0${d}/d01}
          nc2=$gfs/${DOM[$j]}/$wrfo2
          if [ -e $nc2 ];then rm $nc2;fi
          ln -sf $nc1 $nc2
        fi
      done
  #   mcip
      cd $cmaq/data/wrfout
      for f in {0..10};do nc=$gfs/${DOM[$j]}/wrfout_d01_${dates[$f]}_00:00:00;ln -sf $nc wrfout_d0${d}_$f;done
      cd $fcst;~/bin/sub csh run_mcip_DM.csh ${GRD[$j]} 10 >&/dev/null
    done
  else
  #   mcip i=2,d=3
      cd $cmaq/data/wrfout;j=$i;d=3
      for f in {0..10};do nc=$gfs/${DOM[$j]}/wrfout_d01_${dates[$f]}_00:00:00;ln -sf $nc wrfout_d0${d}_$f;done
      cd $fcst;~/bin/sub csh run_mcip_DM.csh ${GRD[$j]} 10 >&/dev/null
  fi
...
```

### combine的背景運作

- 重新整理運作邏輯，讓combine單獨運作
- 第3層因為不必執行run_bcon/run_icon，需確認combine確實完成了，再執行下一個動作。

```bash
#kuang@master /nas1/backup/data/NOAA/NCEP/GFS/YYYY
#$ cat fcst.cs
...
  csh ./run.cctm.${ii}.csh

  # combine PM's
  for id in {0..9};do
    nc=$fcst/${GRD[$i]}/cctm.fcst/daily/CCTM_ACONC_v532_intel_${DOM[$i]}_${datep[$id]}.nc
    ~/bin/sub $fcst/combine.sh $nc
  done
  if [[ $i < 2 ]];then
  # nest down BCON and ICON
    j=$(( $i + 1))
...
 ~/bin/wait_exe combine #make sure all combine executions are finished
...
```

### cmaq_json的同步執行

- CMAQ轉成json檔是逐日進行的，除了複製檔案到imac之外，並沒有不能同步運作的理由。
- 所以只要將複製的動作分散在各日的python檔內執行即可。這就是cmaq_jsonBDay.py的特點。

```python
$ diff cmaq_json3.py cmaq_jsonByDay.py
45c45
< nd=10
---
> nd=1
142a143,145
>     mac=pwd.replace('nas1','home/kuang/mac')
>     os.system('mkdir -p '+mac+dir)
>     os.system('cp '+fnameO+' '+fnameO.replace('nas1','home/kuang/mac'))
178a182,184
>       mac=pwd.replace('nas1','home/kuang/mac')
>       os.system('mkdir -p '+mac+dir)
>       os.system('cp '+fnameO+' '+fnameO.replace('nas1','home/kuang/mac'))
202a209,211
>     mac=pwd.replace('nas1','home/kuang/mac')
>     os.system('mkdir -p '+mac+dir)
>     os.system('cp '+fnameO+' '+fnameO.replace('nas1','home/kuang/mac'))
255a265,268
>
>       mac=pwd.replace('nas1','home/kuang/mac')
>       os.system('mkdir -p '+mac+dir)
>       os.system('cp '+fnameO+' '+fnameO.replace('nas1','home/kuang/mac'))
```

- 執行完cmaq_json整個預報程序就完成了，不需再進行結束之確認

```bash
#kuang@master /nas1/backup/data/NOAA/NCEP/GFS/YYYY
#$ cat fcst.cs
...
  r=${RES[$i]}
  cd /nas1/Data/javascripts/D3js/earthFcst$r/public/data/weather/current
  for id in {0..9};do ~/bin/sub ./cmaq_jsonByDay.py ${dates[$id]};done
```

### 確認執行完成之小工具wait_exe

```bash
#$ cat ~/bin/wait_exe
EXE=$1
while true;do
  n=$(ps -ef|grep ${EXE}|wc -l)
  if [ $n -lt 2 ];then
    break
  else
    sleep 1
  fi
done
```

## 邊界條件之修正

### [WACCM][WACCM]數據之應用

- 詳見[WACCM模式結果之下載、讀取及應用][w1]及[使用WACCM全球預報作為東亞邊界條件][w2]。
- 因為[WACCM][WACCM]數據檔案非常龐大，下載與分析需要5～6 小時，必須提前、另機、平行運作。
- 合併結果將覆蓋`$fcst/grid$res/bcon/BCON_today_CWBWRF_45k`，併入CMAQ的模擬程序。
- BCON檔案的圖像化(2維xz,yz立面濃度檔轉成水平方向)，可以使用[bcon2icon.py](https://sinotec2.github.io/FAQ/2022/10/26/bcon2icon.html)，再套用[VERDI](https://sinotec2.github.io/Focus-on-Air-Quality/utilities/Graphics/VERDI/VERDI_Guide/)。
- [WACCM][WACCM]數據顯示有明顯低估的情形。最後選擇放棄使用。

### [CAMS][CAMS]數據之延長

- 這個方案沒有什麼依據，就是執行24次（6天&times;4次/天）[add_lastHr.py](https://sinotec2.github.io/Focus-on-Air-Quality/utilities/netCDF/add_lastHr/)，將最後一天的變化重複6次。
- 因為CAMS濃度等級有一定的代表性，不致造成顯著高/低估的結果。

## 排放量預備程式之修正

- `nd=5` -> `nd=10`
- 新月份壓縮檔（.tar.gz, .tar.tx）的解壓縮
- 排放量的執行雖然不會佔據太多時間，此處還是將其提前到風場模式之前，安排在背景同步(批次)執行。

### 東亞與中國東南範圍排放量之預備

```bash
...
  cd $gfs
done

#background executions of mk_emis and mk_ptse
for i in 0 1;do
  ii=$(echo ${GRD[$i]}|cut -c5-)
  cd $fcst/grid$ii/smoke
  ~/bin/sub ../../mk_emis.py $BEGD
done
~/bin/sub $gfs/em3.cs

~/bin/wait_exe metgrid #make sure all metgrid executions are finished
...
```

### 臺灣地區排放量之預備

- 整體批次以背景、平行方式計算
- 批次檔內部則為循序執行
- em3.cs 內容

```bash
#cat $fcst/em3.cs
cd $fcst/grid03/smoke
../../mk_emis.py $BEGD
/usr/bin/ncks -O -d LAY,0 TEDS.ncf TEDS0.ncf
/usr/bin/ncatted -a NLAYS,global,o,i,1 TEDS0.ncf
./mk_ptse.py $BEGD
```

## fcst10.cs下載點

- {% include download.html content="10天版本空品預報之作業腳本[fcst10.cs](https://github.com/sinotec2/Focus-on-Air-Quality/blob/main/GridModels/ForecastSystem/fcst10.cs)" %}

[GFS]: <https://en.wikipedia.org/wiki/Global_Forecast_System> "全球預報系統 (GFS) 是一個全球數值天氣預報系統，包含由美國國家氣象局 (NWS) 運行的全球尺度氣象數值預報模式和變分分析。"
[fcst5]: <https://sinotec2.github.io/Focus-on-Air-Quality/GridModels/ForecastSystem/> "逐日WRF與CMAQ預報系統之建置"
[CAMS]: <https://ads.atmosphere.copernicus.eu/cdsapp#!/dataset/cams-global-atmospheric-composition-forecasts?tab=overview> "CAMS每天2次進行全球大氣成分的5天預報，包括50多種氣狀物和7種顆粒物(沙漠塵埃、海鹽、有機物、黑碳、硫酸鹽、硝酸鹽和銨氣溶膠)。初始條件為衛星及地面觀測數據同化分析結果，允許在地面觀測數據覆蓋率低、或無法直接觀測到的大氣污染物進行估計，除此之外，它還使用到基於調查清單或觀測反衍的排放估計，以作為表面的邊界條件。"
[WACCM]: <https://www2.acom.ucar.edu/gcm/waccm> "The Whole Atmosphere Community Climate Model (WACCM) is a comprehensive numerical model, spanning the range of altitude from the Earth's surface to the thermosphere"
[ndown]: <https://sinotec2.github.io/Focus-on-Air-Quality/wind_models/REAL/ndown/> "除了雙向巢狀網格的模擬方式，wrf.exe當然也可以接受循序、單向之巢狀網格模擬，亦即將上層母網格結果，作為下層子網格的初始即邊界條件，所使用的讀取程式，即為ndown.exe。"
[ndowncs]: <https://github.com/sinotec2/Focus-on-Air-Quality/blob/main/GridModels/ForecastSystem/ndown.cs> "由大陸東南wrfout結果切割下層邊界條件之作業腳本"
[FDDA]: <https://zh.wikipedia.org/zh-tw/数据同化> "數據同化，或稱資料同化，是通過數學模型擬合觀測數據的一種漸進方式，通常用於複雜系統的建模和動態預報。"
[ungrib]: <https://sinotec2.github.io/Focus-on-Air-Quality/wind_models/WPS/namelist.wps/#再分析數據之轉檔> "再分析數據之轉檔"
[metgrid]: <https://sinotec2.github.io/Focus-on-Air-Quality/wind_models/WPS/namelist.wps/#metgridexe再分析數據之網格化> "metgrid.exe再分析數據之網格化"
[w1]: <https://sinotec2.github.io/Focus-on-Air-Quality/AQana/GAQuality/3WACCM/> "FAQ->AQ Data Analysis->Global AQ Data Analysis->WACCM模式結果之下載、讀取及應用"
[w2]: <https://sinotec2.github.io/Focus-on-Air-Quality/GridModels/ForecastSystem/11WACCMasBCON/> "FAQ->CMAQ Model System->Forecast System->使用WACCM全球預報作為東亞邊界條件"
