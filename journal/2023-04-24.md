# Monday, April 24, 2023

## Multivariate Logistic Regression in Python

- [Sowmya Krishnan(2020)](https://towardsdatascience.com/multivariate-logistic-regression-in-python-7c6255a286ec)
  - A machine learning technique for classification
  - github resource: [LeadConversion_LogReg](https://github.com/sowmya20/LeadConversion_LogReg)
  

### Model Building

```python
X = leads.drop(['Converted'], 1)
y = leads['Converted']
# Split the dataset into 70% train and 30% test

X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=100)


# Import 'LogisticRegression' and create a LogisticRegression object
from sklearn.linear_model import LogisticRegression
logreg = LogisticRegression()
# Import RFE and select 15 variables
from sklearn.feature_selection import RFE
rfe = RFE(logreg, 15)             
rfe = rfe.fit(X_train, y_train)
```

### test model

```python
col = X_train.columns[rfe.support_]
X_train = X_train[col]
# Import statsmodels

import statsmodels.api as sm
X_train_sm = sm.add_constant(X_train)
logm2 = sm.GLM(y_train, X_train_sm, family = sm.families.Binomial())
res = logm2.fit()
res.summary()
```

### variance_inflation_factor

```python
from statsmodels.stats.outliers_influence import variance_inflation_factor
# Make a VIF dataframe for all the variables present

vif = pd.DataFrame()
vif['Features'] = X_train.columns
vif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]
vif['VIF'] = round(vif['VIF'], 2)
vif = vif.sort_values(by = "VIF", ascending = False)
vif
X_train.drop('Lead Source_Reference', axis = 1, inplace = True)
```

### Precision-Recall Trade-off

```python
# Let's check the overall accuracy
metrics.accuracy_score(y_pred_final['Converted'], y_pred_final.final_predicted)
TP = confusion2[1,1] # true positive 
TN = confusion2[0,0] # true negatives
FP = confusion2[0,1] # false positives
FN = confusion2[1,0] # false negatives
# Calculate Precision
TP/(TP+FP)
# Calculate Recall
TP/(TP+FN)
```